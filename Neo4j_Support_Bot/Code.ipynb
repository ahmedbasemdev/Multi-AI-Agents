{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPIO5-WsNfbR",
        "outputId": "d5060d8c-aed9-4480-ce92-20ae0f7a9e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/375.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_community GitPython youtube-transcript-api sentence-transformers  chromadb openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import (\n",
        "    GitLoader,\n",
        "    YoutubeLoader,\n",
        "    DataFrameLoader\n",
        ")\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool"
      ],
      "metadata": {
        "id": "x5ApE4uYNkgo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge base setup\n",
        "kb_loader = GitLoader(\n",
        "    clone_url=\"https://github.com/neo4j-documentation/knowledge-base\",  # URL of the Git repository to clone\n",
        "    repo_path=\"./repos/kb/\",                                         # Local directory path where the repo will be cloned\n",
        "    branch=\"master\",                                                # The branch of the repository to check out\n",
        "    file_filter=lambda file_path:                                   # A lambda function to filter which files to include\n",
        "        file_path.endswith(\".adoc\") and                             # Include only files that end with '.adoc'\n",
        "        \"articles\" in file_path                                      # AND the file path contains the substring 'articles'\n",
        ")\n",
        "\n",
        "# Load the data from the repository using the configured GitLoader\n",
        "kb_data = kb_loader.load()\n",
        "\n",
        "# Print the number of items (e.g., files or documents) loaded into kb_data\n",
        "print(len(kb_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQ0mLVaOSFc",
        "outputId": "546889fe-0422-4568-959b-8af4368c096c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = CharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=50,)\n",
        "\n",
        "# GDS guides\n",
        "gds_loader = GitLoader(\n",
        "    clone_url=\"https://github.com/neo4j/graph-data-science\",\n",
        "    repo_path=\"./repos/gds/\",\n",
        "    branch=\"master\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".adoc\")\n",
        "    and \"pages\" in file_path,\n",
        ")\n",
        "gds_data = gds_loader.load()\n",
        "\n",
        "gds_data_chunks = splitter.split_documents(gds_data)\n",
        "print(len(gds_data_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rp3n8zQPSUt",
        "outputId": "73cf7c9c-e87a-406c-dddd-7d000a7f68a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2070, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2105, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2069, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 19910, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2952, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2565, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2058, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2665, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2434, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2133, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2228, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2068, which is longer than the specified 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Youtube\n",
        "yt_loader = YoutubeLoader(\"1sRgsEKlUr0\")\n",
        "yt_data = yt_loader.load()\n",
        "yt_data_split = splitter.split_documents(yt_data)\n",
        "print(len(yt_data_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsKY1rs8QcpJ",
        "outputId": "fe2b4dbe-3f6c-4e32-b45b-5d225ef50b3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_url = \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/medium/neo4j_articles.csv\"\n",
        "medium = pd.read_csv(article_url, sep=\";\")\n",
        "medium[\"source\"] = medium[\"url\"]\n",
        "medium_loader = DataFrameLoader(medium[[\"text\",\"source\"]], page_content_column='text')\n",
        "medium_data = medium_loader.load()\n",
        "medium_data_chunks = splitter.split_documents(medium_data)\n",
        "print(len(medium_data_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnzltcyXRWys",
        "outputId": "fd5686a3-b4a9-48dc-f329-74c144770144"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stackoverflow\n",
        "so_data = []\n",
        "for i in range(1, 20):\n",
        "    # Define the Stack Overflow API endpoint and parameters\n",
        "    api_url = \"https://api.stackexchange.com/2.3/questions\"\n",
        "    params = {\n",
        "        \"order\": \"desc\",\n",
        "        \"sort\": \"creation\",\n",
        "        \"filter\": \"!-MBrU_IzpJ5H-AG6Bbzy.X-BYQe(2v-.J\",\n",
        "        \"tagged\": \"neo4j\",\n",
        "        \"site\": \"stackoverflow\",\n",
        "        \"pagesize\": 100,\n",
        "        \"page\": i,\n",
        "    }\n",
        "    # Send GET request to Stack Overflow API\n",
        "    response = requests.get(api_url, params=params)\n",
        "    data = response.json()\n",
        "    # Retrieve the resolved questions\n",
        "    resolved_questions = [\n",
        "        question\n",
        "        for question in data[\"items\"]\n",
        "        if question[\"is_answered\"] and question.get(\"accepted_answer_id\")\n",
        "    ]\n",
        "\n",
        "    # Print the resolved questions\n",
        "    for question in resolved_questions:\n",
        "        text = (\n",
        "            \"Title:\",\n",
        "            question[\"title\"] + \"\\n\" + \"Question:\",\n",
        "            BeautifulSoup(question[\"body\"]).get_text()\n",
        "            + \"\\n\"\n",
        "            + BeautifulSoup(\n",
        "                [x[\"body\"] for x in question[\"answers\"] if x[\"is_accepted\"]][0]\n",
        "            ).get_text(),\n",
        "        )\n",
        "        source = question[\"link\"]\n",
        "        so_data.append(Document(page_content=str(text), metadata={\"source\": source}))\n",
        "print(len(so_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DQgw1BeSMHD",
        "outputId": "2ac31f3a-5ef0-4eb8-991f-ac6bb9a2bbd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "sales_data = medium_data_chunks + yt_data_split\n",
        "sales_store = Chroma.from_documents(\n",
        "    sales_data,\n",
        "    embeddings,\n",
        "    collection_name=\"sales\",\n",
        ")\n",
        "\n",
        "support_data = kb_data + gds_data_chunks + so_data\n",
        "support_store = Chroma.from_documents(\n",
        "    support_data,\n",
        "    embeddings,\n",
        "    collection_name=\"support\",\n",
        ")"
      ],
      "metadata": {
        "id": "P1hQKJ0NSrj4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "open_ai_key = userdata.get('open_ai_key')"
      ],
      "metadata": {
        "id": "D1SUaenTT5JK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    openai_api_key=open_ai_key,\n",
        "    max_tokens=512,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Za0rezVWcd",
        "outputId": "d4b73f35-2e54-4c8a-9b0c-73de2cb7e50c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-cb44648f894e>:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_template = \"\"\"As a Neo4j marketing bot, your goal is to provide accurate and helpful information about Neo4j,\n",
        "a powerful graph database used for building various applications.\n",
        "You should answer user inquiries based on the context provided and avoid making up answers.\n",
        "If you don't know the answer, simply state that you don't know.\n",
        "Remember to provide relevant information about Neo4j's features, benefits,\n",
        "and use cases to assist the user in understanding its value for application development.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "SALES_PROMPT = PromptTemplate(\n",
        "    template=sales_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "-m4NsIWWVoiR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=sales_store.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": SALES_PROMPT},\n",
        "    )"
      ],
      "metadata": {
        "id": "tWYmg4JRVxxa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sales_qa.run(\"What are the main benefits of using Neo4j?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nepRgouiWBrT",
        "outputId": "dce2ef82-e42b-4d3c-bea5-b494ccc45929"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-d324fe17bdbd>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(sales_qa.run(\"What are the main benefits of using Neo4j?\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neo4j is a powerful graph database that offers several benefits:\n",
            "\n",
            "1. High Performance: Neo4j is designed to handle high-volume data and complex queries with ease. It can process large amounts of connected data faster than traditional relational databases.\n",
            "\n",
            "2. Flexibility: Neo4j allows for flexible data modeling. It can easily adapt to changing business requirements without the need for complex joins or expensive schema updates.\n",
            "\n",
            "3. Scalability: Neo4j can scale to handle large amounts of data and high user loads, making it suitable for enterprise-level applications.\n",
            "\n",
            "4. Real-Time Insights: Neo4j's graph model allows for real-time querying and data analysis, providing immediate insights.\n",
            "\n",
            "5. Easy Integration: Neo4j can be easily integrated with various programming languages and frameworks, making it a versatile choice for application development.\n",
            "\n",
            "6. Rich Ecosystem: Neo4j has a rich ecosystem of tools, libraries, and community support, which can help developers build applications more efficiently.\n",
            "\n",
            "7. Advanced Features: Neo4j supports ACID transactions, ensuring data consistency. It also offers enterprise features like role-based access control, query monitoring, and failover capabilities.\n",
            "\n",
            "8. Efficient Data Relationships: Neo4j excels at managing data relationships. It allows for efficient querying and analysis of complex relationships between data entities.\n",
            "\n",
            "9. Use Cases: Neo4j is used in various domains like social networking, recommendation engines, fraud detection, network and IT operations, and more, demonstrating its versatility and robustness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "support_template = \"\"\"\n",
        "As a Neo4j Customer Support bot, you are here to assist with any issues\n",
        "a user might be facing with their graph database implementation and Cypher statements.\n",
        "Please provide as much detail as possible about the problem, how to solve it, and steps a user should take to fix it.\n",
        "If the provided context doesn't provide enough information, you are allowed to use your knowledge and experience to offer you the best possible assistance.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "\n",
        "SUPPORT_PROMPT = PromptTemplate(\n",
        "    template=support_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "support_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=support_store.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": SUPPORT_PROMPT},\n",
        ")\n"
      ],
      "metadata": {
        "id": "AF683dKxWC96"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(support_qa.run(\"\"\"\n",
        "I am having my graph in a VM and i want to use GDS Plugins in my graph.\n",
        "I didn't see any proper documentation to install it in my server where it was working only on locally.\n",
        "Anyone clear me this to install the GDS Plugin in the VM ?\n",
        "\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyO3mZtyWHzo",
        "outputId": "3035272a-a906-4280-ab0d-374a3668a9c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To install the Graph Data Science (GDS) library on a Neo4j server running on a Virtual Machine (VM), you can follow these steps:\n",
            "\n",
            "1. Download the GDS library from the Neo4j Download Center. Make sure to choose the version that matches your Neo4j version.\n",
            "\n",
            "2. Copy the downloaded .jar file to the plugins directory of your Neo4j server. The default location of the plugins directory is `<NEO4J_HOME>/plugins`. If you can't find the plugins directory, you may need to create it.\n",
            "\n",
            "3. Add the following line to your Neo4j configuration file (`<NEO4J_HOME>/conf/neo4j.conf`):\n",
            "\n",
            "```\n",
            "dbms.security.procedures.unrestricted=gds.*\n",
            "```\n",
            "\n",
            "4. Restart your Neo4j server.\n",
            "\n",
            "5. To verify the installation, run the following command in the Neo4j Browser:\n",
            "\n",
            "```\n",
            "RETURN gds.version()\n",
            "```\n",
            "\n",
            "If the GDS library is installed correctly, this command will return the version of the GDS library.\n",
            "\n",
            "Please note that `<NEO4J_HOME>` refers to the directory where Neo4j is installed. The exact path depends on your specific installation.\n",
            "\n",
            "If you encounter any issues during the installation, please provide more details about the error messages you're seeing, and I'll be happy to assist you further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"sales\",\n",
        "        func=sales_qa.run,\n",
        "        description=\"\"\"useful for when a user is interested in various Neo4j information,\n",
        "                       use-cases, or applications. A user is not asking for any debugging, but is only\n",
        "                       interested in general advice for integrating and using Neo4j.\n",
        "                       Input should be a fully formed question.\"\"\"\n",
        "    ),\n",
        "     Tool(\n",
        "        name = \"support\",\n",
        "        func=support_qa.run,\n",
        "        description=\"\"\"useful for when when a user asks to optimize or debug a Cypher statement or needs\n",
        "                       specific instructions how to accomplish a specified task.\n",
        "                       Input should be a fully formed question.\"\"\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "OAFFba2yWJDg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WDyUIRvWXcP",
        "outputId": "e46e4b80-8b3f-4f89-d571-dee93670d9bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-6b26c4f4fa2a>:1: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"\"\"What are some GPT-4 applications with Neo4j?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "JJdFitGRWhS3",
        "outputId": "6207e0f2-9845-488b-d6b2-88683cfab4d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe user is asking for general advice about the applications of GPT-4 with Neo4j. This is not a debugging or optimization question, but rather a request for information.\n",
            "Action: sales\n",
            "Action Input: What are some GPT-4 applications with Neo4j?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAs an AI, I can't predict future developments such as GPT-4. However, based on the capabilities of GPT-3 and the features of Neo4j, potential applications could include:\n",
            "\n",
            "1. Enhanced Natural Language Processing: GPT-4 could potentially offer more advanced natural language processing capabilities. This could be used in conjunction with Neo4j to create more sophisticated chatbots or virtual assistants that can understand and respond to user queries more effectively.\n",
            "\n",
            "2. Advanced Data Analysis: GPT-4 could be used to analyze and interpret the data stored in a Neo4j graph database. This could be used for predictive analytics, trend analysis, or to gain insights from complex data sets.\n",
            "\n",
            "3. Improved Recommendation Systems: GPT-4 could be used to create more advanced recommendation systems. By analyzing user behavior and preferences stored in a Neo4j database, it could provide more accurate and personalized recommendations.\n",
            "\n",
            "4. Enhanced Data Visualization: GPT-4 could potentially create more sophisticated data visualizations based on the data stored in a Neo4j database. This could make it easier for users to understand and interpret complex data.\n",
            "\n",
            "5. Improved Semantic Search: GPT-4 could be used to improve the semantic search capabilities of a system using a Neo4j database. This could allow users to find information more quickly and accurately.\n",
            "\n",
            "Please note that these are speculative applications based on the capabilities of GPT-3 and the features of Neo4j. The actual capabilities and applications of GPT-4 will depend on the advancements made in its development.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Potential applications of GPT-4 with Neo4j could include enhanced natural language processing, advanced data analysis, improved recommendation systems, enhanced data visualization, and improved semantic search. These are speculative applications based on the capabilities of GPT-3 and the features of Neo4j. The actual capabilities and applications of GPT-4 will depend on the advancements made in its development.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Potential applications of GPT-4 with Neo4j could include enhanced natural language processing, advanced data analysis, improved recommendation systems, enhanced data visualization, and improved semantic search. These are speculative applications based on the capabilities of GPT-3 and the features of Neo4j. The actual capabilities and applications of GPT-4 will depend on the advancements made in its development.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"\"\"\n",
        "Hello everyone, is there a way to execute a weighted shortest path query in the Neo4j Community edition?\n",
        "All I have found on the internet was gds library or the algo library, which are both unavailable the community version.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "8SNwLZwmWlrZ",
        "outputId": "1da1e882-4019-4eb4-b806-12d82019418a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe user is asking for specific instructions on how to accomplish a task in Neo4j Community edition. This falls under the support category.\n",
            "\n",
            "Action: support\n",
            "\n",
            "Action Input: \n",
            "Hello everyone, is there a way to execute a weighted shortest path query in the Neo4j Community edition? All I have found on the internet was gds library or the algo library, which are both unavailable the community version.\n",
            "\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mYes, you can execute a weighted shortest path query in Neo4j Community Edition using Cypher's built-in shortestPath function. However, please note that this function only considers the number of hops (relationships) between nodes, and does not take into account any weights on these relationships.\n",
            "\n",
            "If you need to consider weights, you can use APOC Procedures, which is a library of user-defined procedures and functions that works with all editions of Neo4j, including the Community Edition. The APOC path-finding procedures include support for weighted shortest path.\n",
            "\n",
            "Here is an example of how you can use APOC to find the weighted shortest path:\n",
            "\n",
            "```cypher\n",
            "MATCH (start:Node {name: 'Start'}), (end:Node {name: 'End'})\n",
            "CALL apoc.algo.dijkstra(start, end, 'RELATIONSHIP_TYPE', 'weight') YIELD path, weight\n",
            "RETURN path, weight\n",
            "```\n",
            "\n",
            "In this query, 'RELATIONSHIP_TYPE' is the type of the relationships between nodes, and 'weight' is the property on the relationships that represents the weight. The query will return the shortest path from the start node to the end node, considering the weight of the relationships.\n",
            "\n",
            "Please note that you need to install the APOC plugin to use these procedures. You can find more information about APOC and how to install it in the [APOC documentation](https://neo4j.com/labs/apoc/4.1/).\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: Yes, you can execute a weighted shortest path query in Neo4j Community Edition using Cypher's built-in shortestPath function. However, this function only considers the number of hops (relationships) between nodes, and does not take into account any weights on these relationships.\n",
            "\n",
            "If you need to consider weights, you can use APOC Procedures, which is a library of user-defined procedures and functions that works with all editions of Neo4j, including the Community Edition. The APOC path-finding procedures include support for weighted shortest path.\n",
            "\n",
            "Here is an example of how you can use APOC to find the weighted shortest path:\n",
            "\n",
            "```cypher\n",
            "MATCH (start:Node {name: 'Start'}), (end:Node {name: 'End'})\n",
            "CALL apoc.algo.dijkstra(start, end, 'RELATIONSHIP_TYPE', 'weight') YIELD path, weight\n",
            "RETURN path, weight\n",
            "```\n",
            "\n",
            "In this query, 'RELATIONSHIP_TYPE' is the type of the relationships between nodes, and 'weight' is the property on the relationships that represents the weight. The query will return the shortest path from the start node to the end node, considering the weight of the relationships.\n",
            "\n",
            "Please note that you need to install the APOC plugin to use these procedures. You can find more information about APOC and how to install it in the [APOC documentation](https://neo4j.com/labs/apoc/4.1/).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yes, you can execute a weighted shortest path query in Neo4j Community Edition using Cypher's built-in shortestPath function. However, this function only considers the number of hops (relationships) between nodes, and does not take into account any weights on these relationships.\\n\\nIf you need to consider weights, you can use APOC Procedures, which is a library of user-defined procedures and functions that works with all editions of Neo4j, including the Community Edition. The APOC path-finding procedures include support for weighted shortest path.\\n\\nHere is an example of how you can use APOC to find the weighted shortest path:\\n\\n```cypher\\nMATCH (start:Node {name: 'Start'}), (end:Node {name: 'End'})\\nCALL apoc.algo.dijkstra(start, end, 'RELATIONSHIP_TYPE', 'weight') YIELD path, weight\\nRETURN path, weight\\n```\\n\\nIn this query, 'RELATIONSHIP_TYPE' is the type of the relationships between nodes, and 'weight' is the property on the relationships that represents the weight. The query will return the shortest path from the start node to the end node, considering the weight of the relationships.\\n\\nPlease note that you need to install the APOC plugin to use these procedures. You can find more information about APOC and how to install it in the [APOC documentation](https://neo4j.com/labs/apoc/4.1/).\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRP2_al1W387"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}